{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a3PnsyICVY2v",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Parameters — edit these fields\n\n#@markdown ### 出力設定\n#@markdown **出力ファイル名** — ダウンロードされる.docxファイルの名前\nfile_name_download = 'papers_talks_books.docx' #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown ### 期間設定\n#@markdown **開始日** — この日付より後に出版された業績を収集する (YYYY-MM-DD)\nglobalmindate='2025-04-01' #@param {type:\"string\"}\n#@markdown **終了日** — この日付より前に出版された業績を収集する (YYYY-MM-DD)\nglobalmaxdate='2030-04-01' #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown ### 書式設定\n#@markdown **謝辞マーク** — 課題番号が謝辞に含まれる論文に付けるマーク（不要なら空欄）\nsmark='' #@param {type:\"string\"}\n#@markdown **すべて英語名** — Trueで全セクション英語名表記、Falseで講演・書籍・その他は日本語名表記\nallenglish = True #@param {type:\"boolean\"}\n#@markdown **論文ナンバリング** — Trueで論文リストに連番 (1. 2. 3. ...) を付ける\nnumberingPapers = True #@param {type:\"boolean\"}\n#@markdown **査読ありのみ** — Trueでresearchmapで査読ありとされた論文のみ抽出\npeer_reviewed = False #@param {type:\"boolean\"}\n\n#@markdown ---\n#@markdown ### データソース\n#@markdown **スプレッドシートURL** — メンバー情報（researchmap ID、氏名、代表/分担、課題番号）を含むGoogle SheetsのURL\nsheeturl='https://docs.google.com/spreadsheets/d/1T5QtMv4M_peHHM-Zj4oFmS1jHG4voDBJipbEEY0xFQs/edit?usp=sharing' #@param {type:\"string\"}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3508,
     "status": "ok",
     "timestamp": 1584094456008,
     "user": {
      "displayName": "深井洋佑",
      "photoUrl": "",
      "userId": "07275761346057679589"
     },
     "user_tz": -540
    },
    "id": "0rIZIv9QVY3G",
    "outputId": "d2e32d75-856a-4695-b1b6-858a7b64442e",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Imports and setup\nimport requests,json,sys,os, gspread, time, re\nimport numpy as np\nif 'google.colab' in str(get_ipython()):\n    %pip install python-docx\n    from google.colab import files,auth\n    from oauth2client.client import GoogleCredentials\n    outputdirectory = ''\nelse:\n    outputdirectory = '../docx-researchmap-outputs/' #ローカルで実行する場合は保存ファイルのディレクトリを適当に指定\n    os.makedirs(outputdirectory,exist_ok=True)\nfrom docx import Document\nfrom docx.shared import Pt\nfrom docx.enum.text import WD_UNDERLINE\nimport pandas as pd\nfile_name=outputdirectory+file_name_download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlnwDJeCW4PW",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Download spreadsheet\nsheeturl_csv=re.match(\"https://docs.google.com/spreadsheets/d/.+/\",sheeturl).group(0)+\"export?format=csv\"\nname_data=pd.read_csv(sheeturl_csv,dtype=str)\nname_data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1E8b1HjY3oN-",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Parse member data\nmembernum=len(name_data)\n\nallnames=(name_data[\"First name\"]+' '+name_data[\"Surname\"]).to_list()\nallSurname=name_data[\"Surname\"].to_list()\nallnamesJP=(name_data[\"苗字\"]+\" \"+name_data[\"名\"]).to_list()\nallmembers=name_data[\"researchmapID\"].to_list()\nallDB=name_data[\"代表分担協力\"].values\nallDaihyoBuntan=list(allDB)\ngrant_numbers=name_data[\"grantID\"].to_list()\nallmindate=name_data[\"Start date\"].to_list()\nallmaxdate=name_data[\"End date\"].to_list()\n\n# Build extended name list including alternate name spellings\ndef _collect_alt_names(col, db_array):\n    \"\"\"Return (names, db_labels) for non-NaN entries in a column.\"\"\"\n    mask = ~pd.isna(col).values\n    return list(col.values[mask]), list(db_array[mask])\n\nalt_names2, alt_db2 = _collect_alt_names(name_data['著者名（2個目）'], allDB)\nalt_names3, alt_db3 = _collect_alt_names(name_data['著者名（3個目）'], allDB)\n\nnameList = [n.strip() for n in allnames + alt_names2 + alt_names3]\ndaihyobuntanList = allDaihyoBuntan + alt_db2 + alt_db3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNRoF4CLh0lq",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Helper functions\n# Function to set the name order (firstname surname — Western order)\ndef SurnameLast(namesDic,sn):\n    oldnamelist=[]\n    swap=0\n    for indiv in namesDic:\n        oldnamelist=oldnamelist+[indiv['name'].replace(',','').replace('.','')]\n    for name in oldnamelist:\n        if sn in name.split(' '):\n            if name.split(' ').index(sn)==0:\n                swap=1  # surname is first, need to move to end\n                break;\n            else:\n                swap=0  # surname already last, no swap needed\n                break;\n    if swap:\n        newnamelist=[]\n        for name in oldnamelist:\n            namesplit=name.split(' ')\n            names=namesplit[1:]+[namesplit[0]]  # move first to end\n            newnamelist=newnamelist+[' '.join(names)]\n    else:\n        newnamelist=oldnamelist\n    return newnamelist\n\ndef ReturnDictWOerror(dictdata,key,nodata):\n    if key in dictdata.keys():\n        return dictdata[key]\n    else:\n        return nodata\n\ndef ReturnDictContent(dictdata,key,key1,nodata=''):\n    d=ReturnDictWOerror(dictdata,key,nodata)\n    d1=ReturnDictWOerror(dictdata,key1,nodata)\n    if d!=nodata:\n        return d\n    else:\n        return d1\n\ndef commaR(vol,spage):\n    if (vol=='') & (spage==''):\n        return ''\n    elif (vol=='') | (spage==''):\n        return ' '\n    else:\n        return ', '\n\ndef strip_html_tags(text):\n    \"\"\"Remove HTML/XML tags like <scp>, <i>, </i>, etc. from text.\"\"\"\n    return re.sub(r'<[^>]+>', '', text)\n\n# Known bioRxiv DOI prefixes\nBIORXIV_DOI_PREFIXES = ('10.1101/', '10.64898/')\n\n# Journal abbreviation cache and lookup via abbreviso (ISO 4)\n_jname_cache = {}\n\ndef abbreviate_journal(name):\n    \"\"\"Look up ISO 4 abbreviation for a journal name via abbreviso API.\n    Returns the abbreviated name with proper capitalization (e.g. 'Sci. Adv.').\n    Falls back to the original name if the API is unreachable or returns nothing.\"\"\"\n    if not name:\n        return name\n    if name in _jname_cache:\n        return _jname_cache[name]\n    try:\n        r = requests.get(\n            'https://abbreviso.toolforge.org/abbreviso/a/' + requests.utils.quote(name),\n            timeout=5)\n        if r.status_code == 200:\n            abbrev = r.text.strip()\n            if abbrev:\n                _jname_cache[name] = abbrev\n                return abbrev\n    except Exception:\n        pass\n    _jname_cache[name] = name\n    return name\n\ndef add_underlined_run(paragraph, name, nameList, daihyobuntanList):\n    \"\"\"Add a run with D=double-underline, B=single-underline, else plain.\"\"\"\n    if name in nameList:\n        role = daihyobuntanList[nameList.index(name)]\n        if role == 'D':\n            paragraph.add_run(name).underline = WD_UNDERLINE.DOUBLE\n        elif role == 'B':\n            paragraph.add_run(name).underline = True\n        else:\n            paragraph.add_run(name)\n    else:\n        paragraph.add_run(name)\n\ndef sort_by_date_desc(items_dict):\n    \"\"\"Return keys of items_dict sorted by 'date' field, newest first.\"\"\"\n    keys = list(items_dict.keys())\n    datelist = [items_dict[k]['date'] for k in keys]\n    arg = np.argsort(datelist)[::-1]\n    return keys, arg"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0t14rApaVY39",
    "tags": [],
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Download from researchmap API\nurl = \"https://api.researchmap.jp/\"\nitemslist = [\"published_papers\",\"research_projects\",\"misc\",\"presentations\",\"books_etc\"]\njsonfiles={}\nfor name in allmembers:\n  print('downloading: '+name)\n  jsonfiles[name]={}\n  for it in itemslist:\n    r1 = requests.get(url+name+'/'+it)\n    jsonfiles[name][it]=json.loads(r1.text)\n    if 'error' in jsonfiles[name][it].keys():\n      print(jsonfiles[name][it]['error'])\n      print(\"  error in:\"+it)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96xz8YVTh0ly",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Build papers dictionary\ni=0\nPapersDict={}\n\ndoilist=[]\ndoiDict={}\ntitlelist=[]\ntitleDict={}\nfor ids,fullname,surname,dh,mindate,maxdate in zip(allmembers,allnames,allSurname,allDaihyoBuntan,allmindate,allmaxdate):\n    dfP = jsonfiles[ids][\"published_papers\"]\n    dfG = jsonfiles[ids][\"research_projects\"]\n    if 'items' in dfG.keys():\n        grantID=\"0\"\n        for dfs in dfG['items']:\n            if 'identifiers' in dfs.keys():\n                if 'grant_number' in dfs['identifiers'].keys():\n                    if dfs['identifiers']['grant_number'][0] in grant_numbers:\n                        grantID=dfs['rm:id']\n                        break\n    if 'items' in dfP.keys():    \n        for dfs in dfP['items']:\n            if \"authors\" not in dfs.keys():\n                continue\n            if ('identifiers' in dfs.keys()) & (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n                doinum=[0]\n                if 'doi' in dfs['identifiers'].keys():\n                    doinum=dfs['identifiers']['doi']\n\n                PapersDict[i]={}\n                PapersDict[i]['issues']=False\n                PapersDict[i]['preprint']=False\n                correspo=False\n                Ryoiki=False\n                if 'research_project_id' in dfs['identifiers'].keys():\n                    if grantID in dfs['identifiers']['research_project_id']:\n                        Ryoiki=True\n                if \"published_paper_owner_roles\" in dfs.keys():\n                    if \"corresponding\" in dfs[\"published_paper_owner_roles\"]:\n                        correspo=True\n\n                jname=''        \n                if \"publication_name\" in dfs.keys():\n                    jname=strip_html_tags(ReturnDictContent(dfs[\"publication_name\"],'en','ja',''))\n\n                if jname.upper() =='ARXIV':\n                    PapersDict[i]['preprint']=True\n                    if \"arxiv_id\" in dfs['identifiers'].keys():\n                        jname=dfs['identifiers']['arxiv_id'][0] + ' (preprint)'\n                    else:\n                        jname='arXiv'\n                \n                if not(\"publication_name\" in dfs.keys()):\n                    if \"arxiv_id\" in dfs['identifiers'].keys():\n                        jname=dfs['identifiers']['arxiv_id'][0] + ' (preprint)'\n                        PapersDict[i]['preprint']=True\n                    elif doinum[0]!=0:\n                        jname='DOI: '+doinum[0]\n                        PapersDict[i]['preprint']=True\n                    else:\n                        jname='journal unspecified'\n                        PapersDict[i]['issues']=True\n\n                # bioRxiv detection by DOI prefix\n                if doinum[0] != 0 and str(doinum[0]).startswith(BIORXIV_DOI_PREFIXES):\n                    if jname == '' or jname == 'DOI: ' + doinum[0]:\n                        jname = 'bioRxiv'\n                        PapersDict[i]['preprint'] = True\n\n                # Abbreviate real journal names via ISO 4 lookup\n                if not PapersDict[i]['preprint'] and not PapersDict[i]['issues']:\n                    jname = abbreviate_journal(jname)\n\n                Sname=SurnameLast(ReturnDictContent(dfs[\"authors\"],'en','ja',''),surname)\n\n                spage=''\n                if \"starting_page\" in dfs.keys():\n                    if dfs[\"starting_page\"]!='':\n                        spage=dfs[\"starting_page\"]\n\n                vol=''\n                if \"volume\" in dfs.keys():\n                    if dfs[\"volume\"]!='':\n                        vol=' '+dfs[\"volume\"]\n\n                # Track duplicates by DOI\n                if doinum in doilist:\n                    doiDict[doinum[0]]['name']=doiDict[doinum[0]]['name']+[fullname]\n                    doiDict[doinum[0]]['Corresp']=doiDict[doinum[0]]['Corresp']+[correspo]\n                else:\n                    doiDict[doinum[0]]={'name':[fullname],'Corresp':[correspo],'count':0}\n                    doilist=doilist+[doinum[0]]\n                \n                papertitle=strip_html_tags(ReturnDictContent(dfs['paper_title'],'en','ja',''))\n                papid=papertitle.upper().rstrip('.')\n\n                # Track duplicates by title\n                if papid in titlelist:\n                    titleDict[papid]['name'] = titleDict[papid]['name']+[fullname]\n                    titleDict[papid]['Corresp'] = titleDict[papid]['Corresp']+[correspo]                    \n                else:\n                    titlelist = titlelist + [papid]\n                    titleDict[papid] = {'name':[fullname],'Corresp':[correspo],'count':0}\n\n                text1=\"\\\"\"+papertitle+\"\\\"\" +', '\n                text2=jname+','+vol+commaR(vol,spage)+spage+ ' ('+dfs[\"publication_date\"][:4] +').'\n                PapersDict[i]['text1']=text1\n                PapersDict[i]['text2']=text2\n                PapersDict[i]['papid']=papid\n                PapersDict[i]['researcher']=fullname\n                PapersDict[i]['authors']=Sname\n                PapersDict[i]['date']=dfs[\"publication_date\"]\n                PapersDict[i]['referee']=ReturnDictContent(dfs,'referee','referee',False)\n                PapersDict[i]['doi']=doinum[0]\n                PapersDict[i]['ryoiki']=Ryoiki\n                PapersDict[i]['Daihyo']=dh\n                PapersDict[i]['Corresp']=correspo\n                i=i+1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cw-jxR49h0l1",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Build talks dictionary\nTalksDict={}\ni=0\nfor ids,fullname,fullnameJP,dh,mindate,maxdate in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate):\n    dfPr = jsonfiles[ids][\"presentations\"]\n    if 'items' in dfPr.keys():\n        for dfs in dfPr['items']:\n            if all([a in dfs.keys() for a in ['invited',\"presentation_title\",\"event\",'publication_date',\"presenters\"]]):\n                if (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n                    if dfs['invited']:\n                        if ('en' in dfs[\"presenters\"].keys()):\n                            pname=dfs[\"presenters\"][\"en\"][0][\"name\"]\n                        else:\n                            pname=dfs[\"presenters\"][\"ja\"][0][\"name\"]\n                        ename=strip_html_tags(ReturnDictContent(dfs[\"event\"],'en','ja',''))\n                        ptitle=strip_html_tags(ReturnDictContent(dfs[\"presentation_title\"],'en','ja',''))\n                        pdate=dfs[\"publication_date\"]\n                        TalksDict[i]={}\n                        TalksDict[i][\"presenter\"]=fullname\n                        if allenglish:\n                            TalksDict[i]['printname']=fullname\n                        else:\n                            TalksDict[i][\"printname\"]=fullnameJP\n                        TalksDict[i][\"event\"]=ename\n                        TalksDict[i][\"presentation_title\"]=ptitle\n                        TalksDict[i][\"date\"]=pdate\n                        i=i+1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hctp5YUnh0l4",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Build books dictionary\nbooksDict={}\ni=0\nfor ids,fullname,fullnameJP,dh,mindate,maxdate in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate):\n  dfM = jsonfiles[ids][\"books_etc\"]\n  if 'items' in dfM.keys():\n    for dfs in dfM['items']:\n      if all([a in dfs.keys() for a in ['authors',\"book_title\",\"publication_date\"]]):\n        if (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n          if ('ja' in dfs[\"authors\"].keys()):\n              pname=dfs[\"authors\"][\"ja\"][0][\"name\"]\n          else:\n              pname=dfs[\"authors\"][\"en\"][0][\"name\"]\n          ename=strip_html_tags(ReturnDictContent(dfs[\"book_title\"],'ja','en',''))\n          if \"book_owner_range\" in dfs.keys():\n            eoname=\" \\'\"+strip_html_tags(ReturnDictContent(dfs[\"book_owner_range\"],'ja','en',''))+\"\\',\"\n          else:\n            eoname=''\n          if \"book_owner_role\" in dfs.keys():\n            brole=\" (\"+dfs[\"book_owner_role\"]+\"),\"\n          else:\n            brole=','\n          if \"publisher\" in dfs.keys():\n            pub=\" \"+strip_html_tags(ReturnDictContent(dfs[\"publisher\"],'ja','en',''))+\",\"\n          else:\n            pub=''\n          pdate=dfs[\"publication_date\"]\n          booksDict[i]={}\n          booksDict[i]['authors']=fullname\n          if allenglish:\n            booksDict[i]['printname']=fullname\n          else:\n            booksDict[i]['printname']=fullnameJP\n          booksDict[i][\"book_title\"]=' \\\"'+ename+'\\\",'\n          booksDict[i][\"book_owner_role\"]=brole\n          booksDict[i][\"book_owner_range\"]=eoname\n          booksDict[i][\"publisher\"]=pub\n          booksDict[i][\"date\"]=pdate\n          i=i+1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFe7cnwg6qNv",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Build misc dictionary\nmiscDict={}\ni=0\nfor ids,fullname,fullnameJP,dh,mindate,maxdate in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate):\n  dfM = jsonfiles[ids][\"misc\"]\n  if 'items' in dfM.keys():\n    for dfs in dfM['items']:\n      if all([a in dfs.keys() for a in ['authors',\"paper_title\",\"publication_date\",\"publication_name\"]]):\n        if  (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n          if ('ja' in dfs[\"authors\"].keys()):\n              pname=dfs[\"authors\"][\"ja\"][0][\"name\"]\n          else:\n              pname=dfs[\"authors\"][\"en\"][0][\"name\"]\n          ename=strip_html_tags(ReturnDictContent(dfs[\"paper_title\"],'ja','en',''))\n          ptitle=strip_html_tags(ReturnDictContent(dfs[\"publication_name\"],'ja','en',''))\n          pdate=dfs[\"publication_date\"]\n          miscDict[i]={}\n          miscDict[i]['authors']=fullname\n          if allenglish:\n            miscDict[i]['printname']=fullname\n          else:\n            miscDict[i]['printname']=fullnameJP\n\n          miscDict[i][\"paper_title\"]=' \\''+ename+'\\','\n          miscDict[i][\"publication_name\"]=' \\\"'+ptitle+'\\\",'\n          miscDict[i][\"date\"]=pdate\n          i=i+1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAYuiuA3h0l7",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Generate docx\n\nif peer_reviewed:\n    PapersDictSelected={k:PapersDict[k] for k in range(len(PapersDict)) if (PapersDict[k]['date']>globalmindate) & (PapersDict[k]['date']<globalmaxdate)  & (PapersDict[k]['referee'])}\nelse:\n    PapersDictSelected={k:PapersDict[k] for k in range(len(PapersDict)) if (PapersDict[k]['date']>globalmindate) & (PapersDict[k]['date']<globalmaxdate)}   \n\nkeys, arg = sort_by_date_desc(PapersDictSelected)\n\ndocument = Document()\ndocument.add_paragraph('原著論文')\ninds=0\nfor r in arg:\n    inds=inds+1\n    pap=PapersDictSelected[keys[r]]\n    ## to eliminate duplicates of papers\n    # based on DOI\n    if len(doiDict[pap['doi']]['name'])>1:\n        if doiDict[pap['doi']]['count']==1:\n            continue;\n        titleDict[pap['papid']]['count']=1\n        doiDict[pap['doi']]['count']=1\n    # based on paper title\n    if (len(titleDict[pap['papid']]['name'])>1):\n        if titleDict[pap['papid']]['count']==1:\n            continue;\n        titleDict[pap['papid']]['count']=1\n        doiDict[pap['doi']]['count']=1\n\n    if pap['issues']:\n        p = document.add_paragraph('***')\n\n    if numberingPapers:\n        if pap['ryoiki']:\n            p = document.add_paragraph(smark+str(inds)+'. '+pap['text1'])\n        else:\n            p = document.add_paragraph(str(inds)+'. '+pap['text1'])\n    else:\n        if pap['ryoiki']:\n            p = document.add_paragraph(smark+pap['text1'])\n        else:\n            p = document.add_paragraph(pap['text1'])\n    for nm in pap['authors']:\n        if nm in nameList:\n            listedCorrespo = any([c for c,n in zip(doiDict[pap['doi']]['Corresp'] + titleDict[pap['papid']]['Corresp'] , doiDict[pap['doi']]['name'] + titleDict[pap['papid']]['name']) if n==nm])\n            if pap['Corresp'] | listedCorrespo:\n                p.add_run('*')\n            add_underlined_run(p, nm, nameList, daihyobuntanList)\n        else:\n            p.add_run(nm)\n        p.add_run(', ')\n    p.add_run(pap['text2'])\n\nfor r in keys:\n    doiDict[PapersDictSelected[r]['doi']]['count']=0\n    titleDict[PapersDictSelected[r]['papid']]['count']=0\n\n# --- Talks ---\nTalksDictSelected={k:TalksDict[k] for k in range(len(TalksDict)) if (TalksDict[k]['date']>globalmindate) & (TalksDict[k]['date']<globalmaxdate) }\nkeys, arg = sort_by_date_desc(TalksDictSelected)\ndocument.add_paragraph('')\ndocument.add_paragraph('学会発表・講演（招待あり）')\ninds=0\nfor r in arg:\n    inds=inds+1\n    pap=TalksDictSelected[keys[r]]\n    p = document.add_paragraph(str(inds)+'. ')\n    add_underlined_run(p, pap[\"presenter\"], nameList, daihyobuntanList)\n    p.add_run(', \\\"'+pap[\"presentation_title\"]+\"\\\"\")\n    p.add_run(', '+pap[\"event\"])\n    p.add_run(', '+pap[\"date\"]+'.')\n\n# --- Books ---\nbooksDictSelected={k:booksDict[k] for k in range(len(booksDict)) if (booksDict[k]['date']>globalmindate) & (booksDict[k]['date']<globalmaxdate) }\nkeys, arg = sort_by_date_desc(booksDictSelected)\ndocument.add_paragraph('')\ndocument.add_paragraph('書籍')\ninds=0\nfor r in arg:\n    inds=inds+1\n    pap=booksDictSelected[keys[r]]\n    p = document.add_paragraph(str(inds)+'. ')\n    p.add_run(pap[\"printname\"]) \n    p.add_run(pap[\"book_owner_role\"])\n    p.add_run(pap[\"book_owner_range\"])\n    p.add_run(pap[\"book_title\"])\n    p.add_run(pap[\"publisher\"])\n    p.add_run(' '+pap[\"date\"][:7]+'.')\n\n# --- Misc ---\nmiscDictSelected={k:miscDict[k] for k in range(len(miscDict)) if (miscDict[k]['date']>globalmindate) & (miscDict[k]['date']<globalmaxdate) }\nkeys, arg = sort_by_date_desc(miscDictSelected)\ndocument.add_paragraph('')\ndocument.add_paragraph('その他')\ninds=0\nfor r in arg:\n    inds=inds+1\n    pap=miscDictSelected[keys[r]]\n    p = document.add_paragraph(str(inds)+'. ')\n    add_underlined_run(p, pap['authors'], nameList, daihyobuntanList)\n    p.add_run(','+pap[\"paper_title\"])\n    p.add_run(pap[\"publication_name\"])\n    p.add_run(' '+pap[\"date\"]+'.')\n\ntry:\n    document.save(file_name)\nexcept PermissionError:\n    from datetime import datetime\n    stem, ext = os.path.splitext(file_name)\n    file_name = stem + '_' + datetime.now().strftime('%Y%m%d_%H%M%S') + ext\n    document.save(file_name)\n    print('Original file was locked (open in another app?). Saved as: ' + file_name)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1im_KisqqJT",
    "cellView": "form"
   },
   "outputs": [],
   "source": "#@title Download file\nif 'google.colab' in str(get_ipython()):\n    files.download(file_name)"
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "researchmapv2_to_docx.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "metadata": {
   "interpreter": {
    "hash": "b6aaa8c452f1aa53401d42c477fe97baeea39d8952471e90cdbb23434ceb6c90"
   }
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}