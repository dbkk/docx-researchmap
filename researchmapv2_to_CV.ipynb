{"cells":[{"cell_type":"code","execution_count":3,"source":["## いじるのはこのセルのパラメータのみでOK\r\n","\r\n","file_name_download = \"IPB-20210712.docx\" #ダウンロードされるCVのファイル名\r\n","\r\n","globalmindate='2009-06-28' #これより後の業績を集める\r\n","globalmaxdate='2021-07-01' #これより前の業績を集める\r\n","smark='' #researchmapで課題番号紐づけありの論文にマーク付ける場合はここで指定。\r\n","preprintmark='*'\r\n","ryoiki_linked = False #researchmapで課題番号紐づけありの論文のみ出力したい場合はTrue\r\n","allenglish = False #名前表記をすべて英語で統一する場合はTrue, 論文以外の名前表記を日本語にする場合False\r\n","SNfirst = False #英語名前表記をすべて名字先で統一する場合はTrue, 名字後で統一する場合はFalse\r\n","numberingPapers = True #出力の際に論文をナンバリング\r\n","peer_reviewed = False #査読ありのチェックが入った論文だけに限定する場合はTrue\r\n","firstnameInitial = True\r\n","\r\n","ignoremindate=True\r\n","\r\n","sankodata=True # xlsxファイルの読み書きをする場合\r\n","\r\n","docoutputpointsize=11 #11pt出力指定\r\n","\r\n","# 個人の情報を入れたのURL\r\n","sheeturl='https://docs.google.com/spreadsheets/d/1hf2oZbtyu-jCxEiljA8KiUVLZvIybFf0BrfnLc4nuYA/edit?usp=sharing' #作成したgoogle spreadsheetのアドレス\r\n","\r\n","maxpap=99#9\r\n","maxtalk=99#5\r\n","maxsocial=99#5\r\n","maxmed=99#5\r\n","maxsonota=99#3\r\n","maxBSM=99#10\r\n"],"outputs":[],"metadata":{"colab":{},"colab_type":"code","id":"a3PnsyICVY2v"}},{"cell_type":"code","execution_count":4,"source":["import requests,json,sys,os,gspread,time,re,openpyxl,datetime,xlrd\r\n","import numpy as np\r\n","import pandas as pd\r\n","\r\n","if 'google.colab' in str(get_ipython()):\r\n","    %pip install python-docx\r\n","    from google.colab import files,auth\r\n","    from oauth2client.client import GoogleCredentials\r\n","    outputdirectory = ''\r\n","else:\r\n","    outputdirectory = '../docx-researchmap-outputs/' #ローカルで実行する場合は保存ファイルのディレクトリを適当に指定\r\n","    os.makedirs(outputdirectory,exist_ok=True)\r\n","from docx import Document\r\n","from docx.shared import Pt,Mm,RGBColor\r\n","from docx.enum.text import WD_UNDERLINE,WD_LINE_SPACING,WD_BREAK\r\n","\r\n","file_name=outputdirectory+file_name_download"],"outputs":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"colab_type":"code","executionInfo":{"elapsed":3508,"status":"ok","timestamp":1584094456008,"user":{"displayName":"深井洋佑","photoUrl":"","userId":"07275761346057679589"},"user_tz":-540},"id":"0rIZIv9QVY3G","outputId":"d2e32d75-856a-4695-b1b6-858a7b64442e"}},{"cell_type":"code","execution_count":5,"source":["#スプレッドシートをダウンロード\r\n","sheeturl_csv=re.match(\"https://docs.google.com/spreadsheets/d/.+/\",sheeturl).group(0)+\"export?format=csv\"\r\n","name_data=pd.read_csv(sheeturl_csv)\r\n","name_data"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["   班  番号 代表分担協力    Surname First name  苗字   名 researchmapID   grantID  \\\n","0  A   1      B  Kawaguchi      Kyogo  川口  喬吾        kyogok  19H05795   \n","\n","   Start date    End date  著者名（2個目）  著者名（3個目）  \n","0  2019-06-28  2024-03-31       NaN       NaN  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>班</th>\n","      <th>番号</th>\n","      <th>代表分担協力</th>\n","      <th>Surname</th>\n","      <th>First name</th>\n","      <th>苗字</th>\n","      <th>名</th>\n","      <th>researchmapID</th>\n","      <th>grantID</th>\n","      <th>Start date</th>\n","      <th>End date</th>\n","      <th>著者名（2個目）</th>\n","      <th>著者名（3個目）</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>Kawaguchi</td>\n","      <td>Kyogo</td>\n","      <td>川口</td>\n","      <td>喬吾</td>\n","      <td>kyogok</td>\n","      <td>19H05795</td>\n","      <td>2019-06-28</td>\n","      <td>2024-03-31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":5}],"metadata":{"colab":{},"colab_type":"code","id":"nlnwDJeCW4PW"}},{"cell_type":"code","execution_count":6,"source":["membernum=len(name_data)\r\n","\r\n","if SNfirst:\r\n","    allnames=(name_data[\"Surname\"]+' '+name_data[\"First name\"]).to_list()\r\n","else:\r\n","    allnames=(name_data[\"First name\"]+' '+name_data[\"Surname\"]).to_list()\r\n","allSurname=name_data[\"Surname\"].to_list()\r\n","allnamesJP=(name_data[\"苗字\"]+\" \"+name_data[\"名\"]).to_list()\r\n","allgroupnames=name_data[\"班\"].to_list()\r\n","allgroupnum=name_data[\"番号\"].to_list()\r\n","allmembers=name_data[\"researchmapID\"].to_list()\r\n","allDB=name_data[\"代表分担協力\"].values\r\n","allkeikaku=[b for a,b in zip(allgroupnames,allnamesJP) if a in ['A','B','C']]\r\n","allkeikakuPIs=[b for a,b,c in zip(allgroupnames,allnamesJP,allDB) if (a in ['A','B','C']) & (c =='D')]\r\n","allDaihyoBuntan=list(allDB)\r\n","allHan=(name_data[\"班\"]+name_data[\"番号\"].apply(str)).to_list()\r\n","grant_numbers=name_data[\"grantID\"].to_list()\r\n","allmindate=name_data[\"Start date\"].to_list()\r\n","allmaxdate=name_data[\"End date\"].to_list()\r\n","\r\n","#Exception names handling\r\n","altname2,altname3=name_data['著者名（2個目）'],name_data['著者名（3個目）']\r\n","arraltname2,arraltname3=altname2.values,altname3.values\r\n","nameList=allnames+list(arraltname2[~(pd.isna(altname2).values)])+list(arraltname3[~(pd.isna(altname3).values)])\r\n","nameList = [n.strip() for n in nameList]\r\n","daihyobuntanList=allDaihyoBuntan+list(allDB[~(pd.isna(altname2).values)])+list(allDB[~(pd.isna(altname3).values)])"],"outputs":[],"metadata":{"colab":{},"colab_type":"code","id":"1E8b1HjY3oN-"}},{"cell_type":"code","execution_count":7,"source":["# Function to set the name order\r\n","def SurnameFirst(namesDic,sn):\r\n","    oldnamelist=[]\r\n","    swap=0\r\n","    for indiv in namesDic:\r\n","        oldnamelist=oldnamelist+[indiv['name'].replace(',','').replace('.','')]\r\n","        #print(oldnamelist)\r\n","    return SurnameFirstList(oldnamelist,sn)\r\n","\r\n","def SurnameFirstList(oldnamelist,sn):\r\n","    swap=0\r\n","    for name in oldnamelist:\r\n","        if sn in name.split(' '):\r\n","            if name.split(' ').index(sn)==0: # surname first\r\n","                swap= True ^ SNfirst\r\n","                break;\r\n","            else:\r\n","                swap= False ^ SNfirst\r\n","                break;\r\n","    if swap:\r\n","        newnamelist=[]\r\n","        for name in oldnamelist:\r\n","            namesplit=name.split(' ')\r\n","            names=[namesplit[-1]]+namesplit[:-1]\r\n","            newnamelist=newnamelist+[' '.join(names)]\r\n","    else:\r\n","        newnamelist=oldnamelist\r\n","    \r\n","    if SNfirst & firstnameInitial:\r\n","        holdlist=[]\r\n","        for name in newnamelist:\r\n","            namesplit=name.split(' ')\r\n","            names=[namesplit[0]]+[', ']+[namesplit[1][0]]+['.']\r\n","            holdlist=holdlist+[''.join(names)]\r\n","        newnamelist=holdlist\r\n","    elif firstnameInitial:\r\n","        holdlist=[]\r\n","        for name in newnamelist:\r\n","            namesplit=name.split(' ')\r\n","            sn=namesplit[-1]\r\n","            sn=sn.lower()\r\n","            sn=sn[0].upper()+sn[1:]\r\n","            names=[namesplit[0][0]]+['. ']+[sn]\r\n","            holdlist=holdlist+[''.join(names)]\r\n","        newnamelist=holdlist                    \r\n","    return newnamelist\r\n","\r\n","def ReturnDictWOerror(dictdata,key,nodata):\r\n","    if key in dictdata.keys():\r\n","        return dictdata[key]\r\n","    else:\r\n","        return nodata\r\n","\r\n","def ReturnDictContent(dictdata,key,key1,nodata=''):\r\n","    d=ReturnDictWOerror(dictdata,key,nodata)\r\n","    d1=ReturnDictWOerror(dictdata,key1,nodata)\r\n","    if d!=nodata:\r\n","        return d\r\n","    else:\r\n","        return d1\r\n","\r\n","def commaR(vol,spage):\r\n","    if (vol=='') & (spage==''):\r\n","        return ''\r\n","    elif (vol=='') | (spage==''):\r\n","        return ' '\r\n","    else:\r\n","        return ', '"],"outputs":[],"metadata":{"colab":{},"colab_type":"code","id":"FNRoF4CLh0lq"}},{"cell_type":"code","execution_count":8,"source":["url = \"https://api.researchmap.jp/\"\r\n","itemslist = [\"published_papers\",\"research_projects\",\"misc\",\"presentations\",\"books_etc\",\"social_contribution\",\"awards\",\"media_coverage\"]\r\n","jsonfiles={}\r\n","for name in allmembers:\r\n","    print('downloading: '+name)\r\n","    jsonfiles[name]={}\r\n","    for it in itemslist:\r\n","        r1 = requests.get(url+name+'/'+it)\r\n","        jsonfiles[name][it]=json.loads(r1.text)\r\n","        if 'error' in jsonfiles[name][it].keys():\r\n","            print(jsonfiles[name][it]['error'])\r\n","            print(\"  error in:\"+it)"],"outputs":[{"output_type":"stream","name":"stdout","text":["downloading: kyogok\n"]}],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["# make dictionary of all papers\r\n","i=0\r\n","PapersDict={}\r\n","\r\n","doilist=[]\r\n","doiDict={}\r\n","titlelist=[]\r\n","titleDict={}\r\n","#dc = Document()\r\n","for ids,fullname,dh,mindate,maxdate,han in zip(allmembers,allnames,allDaihyoBuntan,allmindate,allmaxdate,allHan):\r\n","    if ignoremindate:\r\n","        mindate='0'\r\n","    surname=fullname.split(' ')[0 if SNfirst else 1]\r\n","    dfP = jsonfiles[ids][\"published_papers\"]\r\n","    dfG = jsonfiles[ids][\"research_projects\"]\r\n","    if 'items' in dfG.keys():\r\n","        grantID=\"0\"\r\n","        for dfs in dfG['items']:\r\n","            if 'identifiers' in dfs.keys():\r\n","                if 'grant_number' in dfs['identifiers'].keys():\r\n","                    if dfs['identifiers']['grant_number'][0] in grant_numbers:\r\n","                        grantID=dfs['rm:id']\r\n","                        break\r\n","    if 'items' in dfP.keys():    \r\n","        for dfs in dfP['items']:\r\n","            if \"authors\" not in dfs.keys():\r\n","                continue\r\n","            if ('identifiers' in dfs.keys()) & (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\r\n","                doinum=[0]\r\n","                if 'doi' in dfs['identifiers'].keys():\r\n","                    doinum=dfs['identifiers']['doi']\r\n","\r\n","                PapersDict[i]={}\r\n","                PapersDict[i]['issues']=False\r\n","                PapersDict[i]['preprint']=False\r\n","                correspo=False\r\n","                Ryoiki=False\r\n","                if 'rm:research_project_id' in dfs['identifiers'].keys():\r\n","                    if grantID in dfs['identifiers']['rm:research_project_id']:\r\n","                        Ryoiki=True\r\n","                        \r\n","                if \"published_paper_owner_roles\" in dfs.keys():\r\n","                    if (\"corresponding\" in dfs[\"published_paper_owner_roles\"]) | (\"last\" in dfs[\"published_paper_owner_roles\"]):\r\n","                        correspo=True\r\n","\r\n","                jname=''        \r\n","                if \"publication_name\" in dfs.keys():\r\n","                    jname=ReturnDictContent(dfs[\"publication_name\"],'en','ja','').upper()\r\n","\r\n","                if jname =='ARXIV':\r\n","                    PapersDict[i]['preprint']=True\r\n","                    if \"arxiv_id\" in dfs['identifiers'].keys():\r\n","                        jname=dfs['identifiers']['arxiv_id'][0] + ' (preprint)'\r\n","                    else:\r\n","                        jname='arxiv'\r\n","                \r\n","                if not(\"publication_name\" in dfs.keys()):\r\n","                    if \"arxiv_id\" in dfs['identifiers'].keys():\r\n","                        jname=dfs['identifiers']['arxiv_id'][0] + ' (preprint)'\r\n","                        PapersDict[i]['preprint']=True\r\n","                    elif doinum[0]!=0:\r\n","                        jname='DOI: '+doinum[0]\r\n","                        PapersDict[i]['preprint']=True\r\n","                    else:\r\n","                        jname='journal unspecified'\r\n","                        PapersDict[i]['issues']=True\r\n","                    \r\n","                Sname=SurnameFirst(ReturnDictContent(dfs[\"authors\"],'en','ja',''),surname)\r\n","\r\n","                spage=''\r\n","                if \"starting_page\" in dfs.keys():\r\n","                    if dfs[\"starting_page\"]!='':\r\n","                        spage=dfs[\"starting_page\"]\r\n","\r\n","                vol=''\r\n","                if \"volume\" in dfs.keys():\r\n","                    if dfs[\"volume\"]!='':\r\n","                        vol=' '+dfs[\"volume\"]\r\n","                if doinum in doilist:\r\n","                    doiDict[doinum[0]]['name']=doiDict[doinum[0]]['name']+[fullname]\r\n","                    doiDict[doinum[0]]['Corresp']=doiDict[doinum[0]]['Corresp']+[correspo]\r\n","                else:\r\n","                    doiDict[doinum[0]]={}\r\n","                    doiDict[doinum[0]]['name']=[fullname]\r\n","                    doiDict[doinum[0]]['Corresp']=[correspo]\r\n","                    doiDict[doinum[0]]['count']=0\r\n","                    doilist=doilist+[doinum[0]]\r\n","                \r\n","                papertitle=ReturnDictContent(dfs['paper_title'],'en','ja','')\r\n","                papid=papertitle.upper().rstrip('.')\r\n","\r\n","                if papid in titlelist:\r\n","                    titleDict[papid]['name'] = titleDict[papid]['name']+[fullname]\r\n","                    titleDict[papid]['Corresp'] = titleDict[papid]['Corresp']+[correspo]                    \r\n","                else:\r\n","                    titlelist = titlelist + [papid]\r\n","                    titleDict[papid] = {}\r\n","                    titleDict[papid]['name'] = [fullname]\r\n","                    titleDict[papid]['Corresp'] = [correspo]\r\n","                    titleDict[papid]['count']=0\r\n","\r\n","                text1=\"\\\"\"+papertitle+\"\\\"\" +', '\r\n","                text2=jname+','+vol+commaR(vol,spage)+spage+ ' ('+dfs[\"publication_date\"][:4] +').'\r\n","                if \"description\" in dfs.keys():\r\n","                    PapersDict[i]['oudan']=ReturnDictWOerror(dfs[\"description\"],'ja','')\r\n","                else:\r\n","                    PapersDict[i]['oudan']=''\r\n","                #print(PapersDict[i]['oudan'])\r\n","                PapersDict[i]['kokunai']=False\r\n","                if \"is_international_journal\" in dfs.keys():\r\n","                    if not dfs[\"is_international_journal\"]:\r\n","                        PapersDict[i]['kokunai']=True\r\n","                PapersDict[i]['text1']=text1\r\n","                PapersDict[i]['text2']=text2\r\n","                PapersDict[i]['papid']=papid\r\n","                PapersDict[i]['researcher']=fullname\r\n","                PapersDict[i]['authors']=Sname\r\n","                PapersDict[i]['date']=dfs[\"publication_date\"]\r\n","                PapersDict[i]['referee']=ReturnDictContent(dfs,'referee','referee',False)\r\n","                PapersDict[i]['doi']=doinum[0]\r\n","                PapersDict[i]['ryoiki']=Ryoiki\r\n","                PapersDict[i]['Daihyo']=dh\r\n","                PapersDict[i]['han']=han\r\n","                PapersDict[i]['Corresp']=correspo\r\n","                i=i+1"],"outputs":[],"metadata":{"colab":{},"colab_type":"code","id":"96xz8YVTh0ly"}},{"cell_type":"code","execution_count":10,"source":["# make dictionary of all talks, 'social_contribution', awards\r\n","TalksDict={}\r\n","SocialContDict={}\r\n","AwardsDict={}\r\n","i,j,l=0,0,0\r\n","for ids,fullname,fullnameJP,dh,mindate,maxdate,han in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate,allHan):\r\n","    dfPr = jsonfiles[ids][\"presentations\"]\r\n","    dfSC = jsonfiles[ids][\"social_contribution\"]\r\n","    dfAw = jsonfiles[ids][\"awards\"]\r\n","    if ignoremindate:\r\n","        mindate='0'\r\n","    if 'items' in dfPr.keys():\r\n","        for dfs in dfPr['items']:\r\n","            if all([a in dfs.keys() for a in [\"presentation_title\",\"event\",'publication_date','presenters']]):\r\n","                if (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\r\n","                    if ('en' in dfs[\"presenters\"].keys()):\r\n","                        pname=dfs[\"presenters\"][\"en\"][0][\"name\"]\r\n","                    else:\r\n","                        pname=dfs[\"presenters\"][\"ja\"][0][\"name\"]\r\n","                    ename=ReturnDictContent(dfs[\"event\"],'ja','en','')\r\n","                    ptitle=ReturnDictContent(dfs[\"presentation_title\"],'ja','en','')\r\n","                    pdate=dfs[\"publication_date\"]\r\n","                    TalksDict[i]={}\r\n","                    TalksDict[i][\"presenter\"]=fullnameJP\r\n","                    if allenglish:\r\n","                        TalksDict[i]['printname']=fullname\r\n","                    else:\r\n","                        TalksDict[i][\"printname\"]=fullnameJP\r\n","                    TalksDict[i][\"event\"]=ename\r\n","                    TalksDict[i][\"presentation_title\"]=ptitle\r\n","                    TalksDict[i][\"date\"]=pdate\r\n","                    TalksDict[i][\"han\"]=han\r\n","                    TalksDict[i][\"invited\"]=ReturnDictWOerror(dfs,'invited',False)\r\n","                    TalksDict[i][\"international\"]=ReturnDictWOerror(dfs,'is_international_presentation',False)\r\n","                    TalksDict[i][\"keyoral\"]= ReturnDictWOerror(dfs,\"presentation_type\",'')\r\n","                    i=i+1\r\n","    if 'items' in dfSC.keys():\r\n","        for dfs in dfSC['items']:\r\n","            if 'from_event_date' in dfs.keys():\r\n","                if (dfs['from_event_date']>=mindate) & (dfs['from_event_date']<=maxdate):\r\n","                    SocialContDict[j]={}\r\n","                    SocialContDict[j]['name']=fullnameJP\r\n","                    SocialContDict[j][\"title\"]=dfs['social_contribution_title']['ja']\r\n","                    SocialContDict[j][\"date\"]=dfs['from_event_date']\r\n","                    SocialContDict[j][\"han\"]=han\r\n","                    if 'event' in dfs.keys():\r\n","                        SocialContDict[j][\"event\"]=ReturnDictContent(dfs[\"event\"],'ja','en','')\r\n","                    else:\r\n","                        SocialContDict[j][\"event\"]=''\r\n","                    j=j+1\r\n","    if 'items' in dfAw.keys():\r\n","        for dfs in dfAw['items']:\r\n","            if (dfs['award_date']>=mindate) & (dfs['award_date']<=maxdate):\r\n","                AwardsDict[l]={}\r\n","                AwardsDict[l]['name']=fullnameJP\r\n","                AwardsDict[l]['award_name']=ReturnDictContent(dfs['award_name'],'ja','en','')\r\n","                if 'association' in dfs.keys():\r\n","                    AwardsDict[l]['association']=ReturnDictContent(dfs['association'],'ja','en','')\r\n","                else:\r\n","                    AwardsDict[l]['association']=''\r\n","                AwardsDict[l]['award_date']=dfs['award_date']\r\n","                l=l+1"],"outputs":[],"metadata":{"colab":{},"colab_type":"code","id":"cw-jxR49h0l1","tags":[]}},{"cell_type":"code","execution_count":11,"source":["# make dictionary of all books_etc\r\n","booksDict={}\r\n","i=0\r\n","for ids,fullname,fullnameJP,dh,mindate,maxdate,han in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate,allHan):\r\n","  dfM = jsonfiles[ids][\"books_etc\"]\r\n","  if ignoremindate:\r\n","    mindate='0'\r\n","  if 'items' in dfM.keys():\r\n","    for dfs in dfM['items']:\r\n","      if all([a in dfs.keys() for a in ['authors',\"book_title\",\"publication_date\"]]):\r\n","        if (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\r\n","          if ('ja' in dfs[\"authors\"].keys()):\r\n","              pname=dfs[\"authors\"][\"ja\"][0][\"name\"]\r\n","          else:\r\n","              pname=dfs[\"authors\"][\"en\"][0][\"name\"]\r\n","          ename=ReturnDictContent(dfs[\"book_title\"],'ja','en','')\r\n","          if \"book_owner_range\" in dfs.keys():\r\n","            eoname=\" \\'\"+ReturnDictContent(dfs[\"book_owner_range\"],'ja','en','')+\"\\',\"\r\n","          else:\r\n","            eoname=''\r\n","          if \"book_owner_role\" in dfs.keys():\r\n","            brole=\" (\"+dfs[\"book_owner_role\"]+\"),\"\r\n","          else:\r\n","            brole=','\r\n","          if \"publisher\" in dfs.keys():\r\n","            pub=\" \"+ReturnDictContent(dfs[\"publisher\"],'ja','en','')+\",\"\r\n","          else:\r\n","            pub=''\r\n","          pdate=dfs[\"publication_date\"]\r\n","          booksDict[i]={}\r\n","          booksDict[i]['authors']=fullname\r\n","          if allenglish:\r\n","            booksDict[i]['printname']=fullname\r\n","          else:\r\n","            booksDict[i]['printname']=fullnameJP\r\n","          booksDict[i][\"book_title\"]=' '+ename+','\r\n","          booksDict[i][\"book_owner_role\"]=brole\r\n","          booksDict[i][\"book_owner_range\"]=eoname\r\n","          booksDict[i][\"publisher\"]=pub\r\n","          booksDict[i][\"date\"]=pdate\r\n","          booksDict[i][\"han\"]=han\r\n","          i=i+1"],"outputs":[],"metadata":{"colab":{},"colab_type":"code","id":"hctp5YUnh0l4"}},{"cell_type":"code","execution_count":12,"source":["# make dictionary of all MISCs\r\n","miscDict={}\r\n","medDict={}\r\n","i,j=0,0\r\n","for ids,fullname,fullnameJP,dh,mindate,maxdate,han in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate,allHan):\r\n","  dfMis = jsonfiles[ids][\"misc\"]\r\n","\r\n","  if ignoremindate:\r\n","    mindate='0'\r\n","\r\n","  if 'items' in dfMis.keys():\r\n","    for dfs in dfMis['items']:\r\n","      if all([a in dfs.keys() for a in ['authors',\"paper_title\",\"publication_date\",\"publication_name\"]]):\r\n","        if  (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\r\n","          if ('ja' in dfs[\"authors\"].keys()):\r\n","              pname=dfs[\"authors\"][\"ja\"][0][\"name\"]\r\n","          else:\r\n","              pname=dfs[\"authors\"][\"en\"][0][\"name\"]\r\n","          ename=ReturnDictContent(dfs[\"paper_title\"],'ja','en','')\r\n","          ptitle=ReturnDictContent(dfs[\"publication_name\"],'ja','en','')\r\n","          pdate=dfs[\"publication_date\"]\r\n","          miscDict[i]={}\r\n","          miscDict[i]['authors']=fullname\r\n","          if allenglish:\r\n","            miscDict[i]['printname']=fullname\r\n","          else:\r\n","            miscDict[i]['printname']=fullnameJP\r\n","\r\n","          miscDict[i][\"paper_title\"]=' \\''+ename+'\\','\r\n","          miscDict[i][\"publication_name\"]=' '+ptitle+','\r\n","          miscDict[i][\"date\"]=pdate\r\n","          miscDict[i][\"han\"]=han\r\n","          i=i+1\r\n","  dfMed = jsonfiles[ids][\"media_coverage\"]\r\n","  if 'items' in dfMed.keys():\r\n","    for dfs in dfMed['items']:\r\n","      if all([a in dfs.keys() for a in [\"media_coverage_title\",\"publication_date\"]]):\r\n","        if  (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\r\n","          ename=ReturnDictContent(dfs[\"media_coverage_title\"],'ja','en','')\r\n","          \r\n","          \r\n","          pdate=dfs[\"publication_date\"]\r\n","          medDict[j]={}\r\n","          medDict[j]['authors']=fullname\r\n","          if allenglish:\r\n","            medDict[j]['printname']=fullname\r\n","          else:\r\n","            medDict[j]['printname']=fullnameJP\r\n","          medDict[j][\"media_coverage_type\"]=''\r\n","          if \"media_coverage_type\" in dfs.keys():\r\n","            medDict[j][\"media_coverage_type\"]=dfs[\"media_coverage_type\"]\r\n","          ptitle=''\r\n","          if \"publisher\" in dfs.keys():\r\n","            ptitle=ReturnDictContent(dfs[\"publisher\"],'ja','en','')+', '\r\n","\r\n","          petitle=''\r\n","          if \"event\" in dfs.keys():\r\n","            petitle=ReturnDictContent(dfs[\"event\"],'ja','en','')+','\r\n","#          print(' '+ptitle+petitle)\r\n","\r\n","          pltitle=''\r\n","          if \"location\" in dfs.keys():\r\n","            pltitle=ReturnDictContent(dfs[\"location\"],'ja','en','')+','\r\n","#          print(' '+ptitle+petitle+pltitle)\r\n","\r\n","          medDict[j][\"paper_title\"]=' \\''+ename+'\\','\r\n","          medDict[j][\"publication_name\"]=' '+ptitle+petitle+pltitle\r\n","          medDict[j][\"date\"]=pdate\r\n","          medDict[j][\"han\"]=han\r\n","          j=j+1"],"outputs":[],"metadata":{"colab":{},"colab_type":"code","id":"nFe7cnwg6qNv"}},{"cell_type":"code","execution_count":14,"source":["# generate docx\r\n","document = Document()\r\n","\r\n","section = document.sections[0]\r\n","section.left_margin = Mm(15)\r\n","section.right_margin = Mm(15)\r\n","section.top_margin = Mm(15)\r\n","section.bottom_margin = Mm(15)\r\n","\r\n","nameListPrint=SurnameFirstList(nameList,'Okada')\r\n","\r\n","if peer_reviewed:\r\n","    refbool=[True]\r\n","else:\r\n","    refbool=[True,False]\r\n","\r\n","if ryoiki_linked:\r\n","    ryoikibool=[True]\r\n","else:\r\n","    ryoikibool=[True,False]\r\n","\r\n","for han in np.unique(allHan):\r\n","\r\n","    PapersDictSelected={k:PapersDict[k] for k in range(len(PapersDict)) if (PapersDict[k]['date']>globalmindate) & (PapersDict[k]['date']<globalmaxdate)  & (PapersDict[k]['referee'] in refbool) & (PapersDict[k]['han']==han) & (PapersDict[k]['ryoiki'] in ryoikibool)}\r\n","    TalksDictSelected={k:TalksDict[k] for k in range(len(TalksDict)) if (TalksDict[k]['date']>globalmindate) & (TalksDict[k]['date']<globalmaxdate) & (TalksDict[k]['han']==han)}\r\n","    booksDictSelected={k:booksDict[k] for k in range(len(booksDict)) if (booksDict[k]['date']>globalmindate) & (booksDict[k]['date']<globalmaxdate) & (booksDict[k]['han']==han)}\r\n","    SocialContDictSelected= {k:SocialContDict[k] for k in range(len(SocialContDict)) if (SocialContDict[k]['date']>globalmindate) & (SocialContDict[k]['date']<globalmaxdate) & (SocialContDict[k]['han']==han)}\r\n","    miscDictSelected={k:miscDict[k] for k in range(len(miscDict)) if (miscDict[k]['date']>globalmindate) & (miscDict[k]['date']<globalmaxdate) & (miscDict[k]['han']==han)}\r\n","    medDictSelected={k:medDict[k] for k in range(len(medDict)) if (medDict[k]['date']>globalmindate) & (medDict[k]['date']<globalmaxdate) & (medDict[k]['han']==han)}\r\n","\r\n","    keys=list(PapersDictSelected.keys())\r\n","    datelist=[PapersDictSelected[r]['date'] for r in keys]\r\n","    arg=np.argsort(datelist)[::-1]\r\n","\r\n","    document.add_paragraph(han[0]+'0'+han[1]+'班')\r\n","\r\n","    countBSM=len(booksDictSelected)+len(SocialContDictSelected)+len(miscDictSelected)\r\n","\r\n","    if countBSM < maxBSM:\r\n","        maxpaps=maxpap+maxBSM-countBSM\r\n","    else:\r\n","        maxpaps=maxpap\r\n","    #print(countBSM)\r\n","    textmax= ', うち'+str(min(maxpaps,len(arg)))+'件抜粋'# if inds>maxpaps else ''\r\n","    CountR=document.add_paragraph('<原著論文> 査読有計'+str(len(arg))+'件'+textmax)\r\n","    CountR.runs[0].bold=True\r\n","    inds=0\r\n","    for r in arg:\r\n","        pap=PapersDictSelected[keys[r]]\r\n","        ## to eliminate duplicates of papers\r\n","        # based on DOI\r\n","        if len(doiDict[pap['doi']]['name'])>1:\r\n","            if doiDict[pap['doi']]['count']==1:\r\n","                continue;\r\n","            titleDict[pap['papid']]['count']=1\r\n","            doiDict[pap['doi']]['count']=1\r\n","        # based on paper title\r\n","        if (len(titleDict[pap['papid']]['name'])>1):\r\n","            if titleDict[pap['papid']]['count']==1:\r\n","                continue;\r\n","            titleDict[pap['papid']]['count']=1\r\n","            doiDict[pap['doi']]['count']=1\r\n","        inds=inds+1\r\n","        if inds<=maxpaps:\r\n","            if pap['issues']:\r\n","                p = document.add_paragraph('***')\r\n","            if numberingPapers:\r\n","                if pap['referee']:\r\n","                    p = document.add_paragraph(str(inds)+'. ')\r\n","                else:\r\n","                    p = document.add_paragraph(preprintmark+str(inds)+'. ')\r\n","            else:\r\n","                if pap['referee']:\r\n","                    p = document.add_paragraph('')\r\n","                else:\r\n","                    p = document.add_paragraph(preprintmark)\r\n","\r\n","            for nm in pap['authors']:\r\n","                if nm in nameListPrint:\r\n","                    listedCorrespo = any([c for c,n in zip(doiDict[pap['doi']]['Corresp'] + titleDict[pap['papid']]['Corresp'] , doiDict[pap['doi']]['name'] + titleDict[pap['papid']]['name']) if n==nm])\r\n","                    # print(nm,listedCorrespo)\r\n","                    # if pap['Corresp'] | listedCorrespo:\r\n","                    #     p.add_run('*')\r\n","                    if daihyobuntanList[nameListPrint.index(nm)]=='D':\r\n","                        run=p.add_run()\r\n","                        run.text=nm\r\n","                        run.underline = WD_UNDERLINE.DOUBLE\r\n","                        run.font.bold =True\r\n","                    elif daihyobuntanList[nameListPrint.index(nm)]=='B':\r\n","                        run=p.add_run()\r\n","                        run.text=nm\r\n","                        run.underline = True\r\n","                        run.font.bold =True\r\n","                    else:\r\n","                        p.add_run(nm)\r\n","                else:\r\n","                    p.add_run(nm)\r\n","                p.add_run(', ')\r\n","            p.add_run(pap['text1'])\r\n","            p.add_run(pap['text2'])\r\n","\r\n","    if inds != len(arg):\r\n","        textmax= ', うち'+str(min(maxpaps,inds))+'件抜粋'# if inds>maxpaps else ''\r\n","        CountR.text='<原著論文> 査読有計'+str(inds)+'件'+textmax\r\n","        CountR.runs[0].bold=True\r\n","        #replaced_text = paragraph.text.replace(\"before\",\"after\")\r\n","\r\n","    for r in keys:\r\n","        doiDict[PapersDictSelected[r]['doi']]['count']=0\r\n","        titleDict[PapersDictSelected[r]['papid']]['count']=0\r\n","\r\n","\r\n","    keys=list(TalksDictSelected.keys())\r\n","    datelist=[TalksDictSelected[r]['date'] for r in keys]\r\n","    arg=np.argsort(datelist)[::-1]\r\n","    #document.add_paragraph('')\r\n","    textmax= ', うち'+str(min(maxtalk,len(arg)))+'件抜粋'# if len(arg)>maxtalk else ''\r\n","    CountG=document.add_paragraph('<学会発表・講演> 計'+str(len(arg))+'件'+textmax)\r\n","    CountG.runs[0].bold=True\r\n","\r\n","    inds=0\r\n","    for r in arg:\r\n","        inds=inds+1\r\n","        if inds<=maxtalk:\r\n","            pap=TalksDictSelected[keys[r]]\r\n","            p = document.add_paragraph(str(inds)+'. ')\r\n","            nm=pap[\"presenter\"]\r\n","            p.add_run(pap[\"printname\"])\r\n","            p.add_run(', \\\"'+pap[\"presentation_title\"]+\"\\\"\")\r\n","            p.add_run(', '+pap[\"event\"])\r\n","            p.add_run(', '+pap[\"date\"]+'.')\r\n","\r\n","    keys=list(booksDictSelected.keys())\r\n","    datelist=[booksDictSelected[r]['date'] for r in keys]\r\n","    arg=np.argsort(datelist)[::-1]\r\n","    #document.add_paragraph('')\r\n","    CountB=document.add_paragraph('<書籍> 計'+str(len(arg))+'件')\r\n","    CountB.runs[0].bold=True\r\n","    inds=0\r\n","    for r in arg:\r\n","        inds=inds+1\r\n","        pap=booksDictSelected[keys[r]]\r\n","        p = document.add_paragraph(str(inds)+'. ')\r\n","        nm=pap['authors']\r\n","        p.add_run(pap[\"printname\"]) \r\n","        p.add_run(pap[\"book_owner_role\"])\r\n","        p.add_run(pap[\"book_owner_range\"])\r\n","        p.add_run(pap[\"book_title\"])\r\n","        p.add_run(pap[\"publisher\"])\r\n","        p.add_run(' '+pap[\"date\"][:7]+'.')\r\n","\r\n","    keys=list(SocialContDictSelected.keys())\r\n","    datelist=[SocialContDictSelected[r]['date'] for r in keys]\r\n","    arg=np.argsort(datelist)[::-1]\r\n","    textmax= ', うち'+str(min(maxsocial,len(arg)))+'件抜粋'# if len(arg)>maxsocial else ''\r\n","    CountO=document.add_paragraph('<アウトリーチ> 計'+str(len(arg))+'件'+textmax)\r\n","    CountO.runs[0].bold=True\r\n","    inds=0\r\n","    for r in arg:\r\n","        inds=inds+1\r\n","        if inds<=maxsocial:\r\n","            pap=SocialContDictSelected[keys[r]]\r\n","            p = document.add_paragraph(str(inds)+'. ')\r\n","            p.add_run(pap[\"name\"])\r\n","            p.add_run(', '+pap[\"title\"])\r\n","            p.add_run(', '+pap[\"event\"])\r\n","            p.add_run(' '+pap[\"date\"]+'.')\r\n","\r\n","    keys=list(medDictSelected.keys())\r\n","    datelist=[medDictSelected[r]['date'] for r in keys]\r\n","    arg=np.argsort(datelist)[::-1]\r\n","    #document.add_paragraph('')\r\n","    textmax= ', うち'+str(min(maxmed,len(arg)))+'件抜粋'# if len(arg)>maxmed else ''\r\n","    CountP=document.add_paragraph('<報道> 計'+str(len(arg))+'件'+textmax)\r\n","    CountP.runs[0].bold=True\r\n","    inds=0\r\n","    for r in arg:\r\n","        inds=inds+1\r\n","        if inds<=maxsonota:\r\n","            pap=medDictSelected[keys[r]]\r\n","            p = document.add_paragraph(str(inds)+'. ')\r\n","            nm=pap['authors']\r\n","            p.add_run(pap[\"printname\"])\r\n","            p.add_run(','+pap[\"paper_title\"])\r\n","            p.add_run(pap[\"publication_name\"])\r\n","            p.add_run(' '+pap[\"date\"]+'.')\r\n","\r\n","    keys=list(miscDictSelected.keys())\r\n","    datelist=[miscDictSelected[r]['date'] for r in keys]\r\n","    arg=np.argsort(datelist)[::-1]\r\n","    #document.add_paragraph('')\r\n","    textmax= ', うち'+str(min(maxsonota,len(arg)))+'件抜粋'# if len(arg)>maxsonota else ''\r\n","    CountM=document.add_paragraph('<その他> 計'+str(len(arg))+'件'+textmax)\r\n","    CountM.runs[0].bold=True\r\n","    inds=0\r\n","    for r in arg:\r\n","        inds=inds+1\r\n","        if inds<=maxsonota:\r\n","            pap=miscDictSelected[keys[r]]\r\n","            p = document.add_paragraph(str(inds)+'. ')\r\n","            nm=pap['authors']\r\n","            p.add_run(pap[\"printname\"])\r\n","            p.add_run(','+pap[\"paper_title\"])\r\n","            p.add_run(pap[\"publication_name\"])\r\n","            p.add_run(' '+pap[\"date\"]+'.')\r\n","    p = document.add_paragraph()\r\n","\r\n","    p.add_run().add_break(WD_BREAK.PAGE) # page break\r\n","\r\n","for paragraph in document.paragraphs:\r\n","    paragraph.style = document.styles['Normal']\r\n","    paragraph.paragraph_format.space_before = Pt(2)\r\n","    paragraph.paragraph_format.space_after = Pt(2)\r\n","    for run in paragraph.runs:\r\n","        run.font.size = Pt(docoutputpointsize)\r\n","document.save(file_name)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["if ('google.colab' in str(get_ipython())):\r\n","    files.download(file_name)"],"outputs":[],"metadata":{}}],"metadata":{"colab":{"collapsed_sections":[],"name":"researchmapv2_to_docx.ipynb","provenance":[]},"interpreter":{"hash":"c3500e5973634b4432116d19786601ecc506aed96e4bde06851a6f10663e815f"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"metadata":{"interpreter":{"hash":"b6aaa8c452f1aa53401d42c477fe97baeea39d8952471e90cdbb23434ceb6c90"}},"toc":{"colors":{"hover_highlight":"#DAA520","navigate_num":"#000000","navigate_text":"#333333","running_highlight":"#FF0000","selected_highlight":"#FFD700","sidebar_border":"#EEEEEE","wrapper_background":"#FFFFFF"},"moveMenuLeft":true,"nav_menu":{"height":"12px","width":"252px"},"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":4,"toc_cell":false,"toc_section_display":"block","toc_window_display":false,"widenNotebook":false}},"nbformat":4,"nbformat_minor":2}