{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{},"colab_type":"code","id":"a3PnsyICVY2v"},"outputs":[],"source":["## いじるのはこのセルのパラメータのみでOK\n","\n","file_name_download = \"IPB-20210712.docx\" #ダウンロードされるCVのファイル名\n","\n","globalmindate='2009-06-28' #これより後の業績を集める\n","globalmaxdate='2021-07-01' #これより前の業績を集める\n","smark='' #researchmapで課題番号紐づけありの論文にマーク付ける場合はここで指定。\n","preprintmark='*'\n","ryoiki_linked = False #researchmapで課題番号紐づけありの論文のみ出力したい場合はTrue\n","allenglish = False #名前表記をすべて英語で統一する場合はTrue, 論文以外の名前表記を日本語にする場合False\n","SNfirst = False #英語名前表記をすべて名字先で統一する場合はTrue, 名字後で統一する場合はFalse\n","numberingPapers = True #出力の際に論文をナンバリング\n","peer_reviewed = False #査読ありのチェックが入った論文だけに限定する場合はTrue\n","firstnameInitial = True\n","\n","ignoremindate=True\n","\n","sankodata=True # xlsxファイルの読み書きをする場合\n","\n","docoutputpointsize=11 #11pt出力指定\n","\n","# 個人の情報を入れたのURL\n","sheeturl='https://docs.google.com/spreadsheets/d/1hf2oZbtyu-jCxEiljA8KiUVLZvIybFf0BrfnLc4nuYA/edit?usp=sharing' #作成したgoogle spreadsheetのアドレス\n","\n","maxpap=99#9\n","maxtalk=99#5\n","maxsocial=99#5\n","maxmed=99#5\n","maxsonota=99#3\n","maxBSM=99#10\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"colab_type":"code","executionInfo":{"elapsed":3508,"status":"ok","timestamp":1584094456008,"user":{"displayName":"深井洋佑","photoUrl":"","userId":"07275761346057679589"},"user_tz":-540},"id":"0rIZIv9QVY3G","outputId":"d2e32d75-856a-4695-b1b6-858a7b64442e"},"outputs":[],"source":["#@title 出力ファイルの設定\n","import requests,json,sys,os,gspread,time,re,openpyxl,datetime,xlrd\n","import numpy as np\n","import pandas as pd\n","\n","if 'google.colab' in str(get_ipython()):\n","    %pip install python-docx\n","    from google.colab import files,auth\n","    from oauth2client.client import GoogleCredentials\n","    outputdirectory = ''\n","else:\n","    outputdirectory = '../docx-researchmap-outputs/' #ローカルで実行する場合は保存ファイルのディレクトリを適当に指定\n","    os.makedirs(outputdirectory,exist_ok=True)\n","from docx import Document\n","from docx.shared import Pt,Mm,RGBColor\n","from docx.enum.text import WD_UNDERLINE,WD_LINE_SPACING,WD_BREAK\n","\n","file_name=outputdirectory+file_name_download"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{},"colab_type":"code","id":"nlnwDJeCW4PW"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>班</th>\n","      <th>番号</th>\n","      <th>代表分担協力</th>\n","      <th>Surname</th>\n","      <th>First name</th>\n","      <th>苗字</th>\n","      <th>名</th>\n","      <th>researchmapID</th>\n","      <th>grantID</th>\n","      <th>Start date</th>\n","      <th>End date</th>\n","      <th>著者名（2個目）</th>\n","      <th>著者名（3個目）</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>Kawaguchi</td>\n","      <td>Kyogo</td>\n","      <td>川口</td>\n","      <td>喬吾</td>\n","      <td>kyogok</td>\n","      <td>19H05795</td>\n","      <td>2019-06-28</td>\n","      <td>2024-03-31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   班  番号 代表分担協力    Surname First name  苗字   名 researchmapID   grantID  \\\n","0  A   1      B  Kawaguchi      Kyogo  川口  喬吾        kyogok  19H05795   \n","\n","   Start date    End date  著者名（2個目）  著者名（3個目）  \n","0  2019-06-28  2024-03-31       NaN       NaN  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#@title スプレッドシートをダウンロード\n","sheeturl_csv=re.match(\"https://docs.google.com/spreadsheets/d/.+/\",sheeturl).group(0)+\"export?format=csv\"\n","name_data=pd.read_csv(sheeturl_csv)\n","name_data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{},"colab_type":"code","id":"1E8b1HjY3oN-"},"outputs":[],"source":["#@title 名前表記のリストを作成\n","membernum=len(name_data)\n","\n","if SNfirst:\n","    allnames=(name_data[\"Surname\"]+' '+name_data[\"First name\"]).to_list()\n","else:\n","    allnames=(name_data[\"First name\"]+' '+name_data[\"Surname\"]).to_list()\n","allSurname=name_data[\"Surname\"].to_list()\n","allnamesJP=(name_data[\"苗字\"]+\" \"+name_data[\"名\"]).to_list()\n","allgroupnames=name_data[\"班\"].to_list()\n","allgroupnum=name_data[\"番号\"].to_list()\n","allmembers=name_data[\"researchmapID\"].to_list()\n","allDB=name_data[\"代表分担協力\"].values\n","allkeikaku=[b for a,b in zip(allgroupnames,allnamesJP) if a in ['A','B','C']]\n","allkeikakuPIs=[b for a,b,c in zip(allgroupnames,allnamesJP,allDB) if (a in ['A','B','C']) & (c =='D')]\n","allDaihyoBuntan=list(allDB)\n","allHan=(name_data[\"班\"]+name_data[\"番号\"].apply(str)).to_list()\n","grant_numbers=name_data[\"grantID\"].to_list()\n","allmindate=name_data[\"Start date\"].to_list()\n","allmaxdate=name_data[\"End date\"].to_list()\n","\n","#Exception names handling\n","altname2,altname3=name_data['著者名（2個目）'],name_data['著者名（3個目）']\n","arraltname2,arraltname3=altname2.values,altname3.values\n","nameList=allnames+list(arraltname2[~(pd.isna(altname2).values)])+list(arraltname3[~(pd.isna(altname3).values)])\n","nameList = [n.strip() for n in nameList]\n","daihyobuntanList=allDaihyoBuntan+list(allDB[~(pd.isna(altname2).values)])+list(allDB[~(pd.isna(altname3).values)])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{},"colab_type":"code","id":"FNRoF4CLh0lq"},"outputs":[],"source":["#@title 関数定義\n","def SurnameFirst(namesDic,sn):\n","    oldnamelist=[]\n","    swap=0\n","    for indiv in namesDic:\n","        oldnamelist=oldnamelist+[indiv['name'].replace(',','').replace('.','')]\n","        #print(oldnamelist)\n","    return SurnameFirstList(oldnamelist,sn)\n","\n","def SurnameFirstList(oldnamelist,sn):\n","    swap=0\n","    for name in oldnamelist:\n","        if sn in name.split(' '):\n","            if name.split(' ').index(sn)==0: # surname first\n","                swap= True ^ SNfirst\n","                break;\n","            else:\n","                swap= False ^ SNfirst\n","                break;\n","    if swap:\n","        newnamelist=[]\n","        for name in oldnamelist:\n","            namesplit=name.split(' ')\n","            names=[namesplit[-1]]+namesplit[:-1]\n","            newnamelist=newnamelist+[' '.join(names)]\n","    else:\n","        newnamelist=oldnamelist\n","    \n","    if SNfirst & firstnameInitial:\n","        holdlist=[]\n","        for name in newnamelist:\n","            namesplit=name.split(' ')\n","            names=[namesplit[0]]+[', ']+[namesplit[1][0]]+['.']\n","            holdlist=holdlist+[''.join(names)]\n","        newnamelist=holdlist\n","    elif firstnameInitial:\n","        holdlist=[]\n","        for name in newnamelist:\n","            namesplit=name.split(' ')\n","            sn=namesplit[-1]\n","            sn=sn.lower()\n","            sn=sn[0].upper()+sn[1:]\n","            names=[namesplit[0][0]]+['. ']+[sn]\n","            holdlist=holdlist+[''.join(names)]\n","        newnamelist=holdlist                    \n","    return newnamelist\n","\n","def ReturnDictWOerror(dictdata,key,nodata):\n","    if key in dictdata.keys():\n","        return dictdata[key]\n","    else:\n","        return nodata\n","\n","def ReturnDictContent(dictdata,key,key1,nodata=''):\n","    d=ReturnDictWOerror(dictdata,key,nodata)\n","    d1=ReturnDictWOerror(dictdata,key1,nodata)\n","    if d!=nodata:\n","        return d\n","    else:\n","        return d1\n","\n","def commaR(vol,spage):\n","    if (vol=='') & (spage==''):\n","        return ''\n","    elif (vol=='') | (spage==''):\n","        return ' '\n","    else:\n","        return ', '"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["downloading: kyogok\n"]}],"source":["#@title Researchmapからデータのダウンロード\n","url = \"https://api.researchmap.jp/\"\n","itemslist = [\"published_papers\",\"research_projects\",\"misc\",\"presentations\",\"books_etc\",\"social_contribution\",\"awards\",\"media_coverage\"]\n","jsonfiles={}\n","for name in allmembers:\n","    print('downloading: '+name)\n","    jsonfiles[name]={}\n","    for it in itemslist:\n","        r1 = requests.get(url+name+'/'+it)\n","        jsonfiles[name][it]=json.loads(r1.text)\n","        if 'error' in jsonfiles[name][it].keys():\n","            print(jsonfiles[name][it]['error'])\n","            print(\"  error in:\"+it)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{},"colab_type":"code","id":"96xz8YVTh0ly"},"outputs":[],"source":["#@title 論文(\"published_papers\")データの作成\n","i=0\n","PapersDict={}\n","\n","doilist=[]\n","doiDict={}\n","titlelist=[]\n","titleDict={}\n","#dc = Document()\n","for ids,fullname,dh,mindate,maxdate,han in zip(allmembers,allnames,allDaihyoBuntan,allmindate,allmaxdate,allHan):\n","    if ignoremindate:\n","        mindate='0'\n","    surname=fullname.split(' ')[0 if SNfirst else 1]\n","    dfP = jsonfiles[ids][\"published_papers\"]\n","    dfG = jsonfiles[ids][\"research_projects\"]\n","    if 'items' in dfG.keys():\n","        grantID=\"0\"\n","        for dfs in dfG['items']:\n","            if 'identifiers' in dfs.keys():\n","                if 'grant_number' in dfs['identifiers'].keys():\n","                    if dfs['identifiers']['grant_number'][0] in grant_numbers:\n","                        grantID=dfs['rm:id']\n","                        break\n","    if 'items' in dfP.keys():    \n","        for dfs in dfP['items']:\n","            if \"authors\" not in dfs.keys():\n","                continue\n","            if ('identifiers' in dfs.keys()) & (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n","                doinum=[0]\n","                if 'doi' in dfs['identifiers'].keys():\n","                    doinum=dfs['identifiers']['doi']\n","\n","                PapersDict[i]={}\n","                PapersDict[i]['issues']=False\n","                PapersDict[i]['preprint']=False\n","                correspo=False\n","                Ryoiki=False\n","                if 'rm:research_project_id' in dfs['identifiers'].keys():\n","                    if grantID in dfs['identifiers']['rm:research_project_id']:\n","                        Ryoiki=True\n","                        \n","                if \"published_paper_owner_roles\" in dfs.keys():\n","                    if (\"corresponding\" in dfs[\"published_paper_owner_roles\"]) | (\"last\" in dfs[\"published_paper_owner_roles\"]):\n","                        correspo=True\n","\n","                jname=''        \n","                if \"publication_name\" in dfs.keys():\n","                    jname=ReturnDictContent(dfs[\"publication_name\"],'en','ja','').upper()\n","\n","                if jname =='ARXIV':\n","                    PapersDict[i]['preprint']=True\n","                    if \"arxiv_id\" in dfs['identifiers'].keys():\n","                        jname=dfs['identifiers']['arxiv_id'][0] + ' (preprint)'\n","                    else:\n","                        jname='arxiv'\n","                \n","                if not(\"publication_name\" in dfs.keys()):\n","                    if \"arxiv_id\" in dfs['identifiers'].keys():\n","                        jname=dfs['identifiers']['arxiv_id'][0] + ' (preprint)'\n","                        PapersDict[i]['preprint']=True\n","                    elif doinum[0]!=0:\n","                        jname='DOI: '+doinum[0]\n","                        PapersDict[i]['preprint']=True\n","                    else:\n","                        jname='journal unspecified'\n","                        PapersDict[i]['issues']=True\n","                    \n","                Sname=SurnameFirst(ReturnDictContent(dfs[\"authors\"],'en','ja',''),surname)\n","\n","                spage=''\n","                if \"starting_page\" in dfs.keys():\n","                    if dfs[\"starting_page\"]!='':\n","                        spage=dfs[\"starting_page\"]\n","\n","                vol=''\n","                if \"volume\" in dfs.keys():\n","                    if dfs[\"volume\"]!='':\n","                        vol=' '+dfs[\"volume\"]\n","                if doinum in doilist:\n","                    doiDict[doinum[0]]['name']=doiDict[doinum[0]]['name']+[fullname]\n","                    doiDict[doinum[0]]['Corresp']=doiDict[doinum[0]]['Corresp']+[correspo]\n","                else:\n","                    doiDict[doinum[0]]={}\n","                    doiDict[doinum[0]]['name']=[fullname]\n","                    doiDict[doinum[0]]['Corresp']=[correspo]\n","                    doiDict[doinum[0]]['count']=0\n","                    doilist=doilist+[doinum[0]]\n","                \n","                papertitle=ReturnDictContent(dfs['paper_title'],'en','ja','')\n","                papid=papertitle.upper().rstrip('.')\n","\n","                if papid in titlelist:\n","                    titleDict[papid]['name'] = titleDict[papid]['name']+[fullname]\n","                    titleDict[papid]['Corresp'] = titleDict[papid]['Corresp']+[correspo]                    \n","                else:\n","                    titlelist = titlelist + [papid]\n","                    titleDict[papid] = {}\n","                    titleDict[papid]['name'] = [fullname]\n","                    titleDict[papid]['Corresp'] = [correspo]\n","                    titleDict[papid]['count']=0\n","\n","                text1=\"\\\"\"+papertitle+\"\\\"\" +', '\n","                text2=jname+','+vol+commaR(vol,spage)+spage+ ' ('+dfs[\"publication_date\"][:4] +').'\n","                if \"description\" in dfs.keys():\n","                    PapersDict[i]['oudan']=ReturnDictWOerror(dfs[\"description\"],'ja','')\n","                else:\n","                    PapersDict[i]['oudan']=''\n","                #print(PapersDict[i]['oudan'])\n","                PapersDict[i]['kokunai']=False\n","                if \"is_international_journal\" in dfs.keys():\n","                    if not dfs[\"is_international_journal\"]:\n","                        PapersDict[i]['kokunai']=True\n","                PapersDict[i]['text1']=text1\n","                PapersDict[i]['text2']=text2\n","                PapersDict[i]['papid']=papid\n","                PapersDict[i]['researcher']=fullname\n","                PapersDict[i]['authors']=Sname\n","                PapersDict[i]['date']=dfs[\"publication_date\"]\n","                PapersDict[i]['referee']=ReturnDictContent(dfs,'referee','referee',False)\n","                PapersDict[i]['doi']=doinum[0]\n","                PapersDict[i]['ryoiki']=Ryoiki\n","                PapersDict[i]['Daihyo']=dh\n","                PapersDict[i]['han']=han\n","                PapersDict[i]['Corresp']=correspo\n","                i=i+1"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{},"colab_type":"code","id":"cw-jxR49h0l1","tags":[]},"outputs":[],"source":["#@title 講演・社会貢献・賞(talks, 'social_contribution', awards)データの作成\n","TalksDict={}\n","SocialContDict={}\n","AwardsDict={}\n","i,j,l=0,0,0\n","for ids,fullname,fullnameJP,dh,mindate,maxdate,han in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate,allHan):\n","    dfPr = jsonfiles[ids][\"presentations\"]\n","    dfSC = jsonfiles[ids][\"social_contribution\"]\n","    dfAw = jsonfiles[ids][\"awards\"]\n","    if ignoremindate:\n","        mindate='0'\n","    if 'items' in dfPr.keys():\n","        for dfs in dfPr['items']:\n","            if all([a in dfs.keys() for a in [\"presentation_title\",\"event\",'publication_date','presenters']]):\n","                if (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n","                    if ('en' in dfs[\"presenters\"].keys()):\n","                        pname=dfs[\"presenters\"][\"en\"][0][\"name\"]\n","                    else:\n","                        pname=dfs[\"presenters\"][\"ja\"][0][\"name\"]\n","                    ename=ReturnDictContent(dfs[\"event\"],'ja','en','')\n","                    ptitle=ReturnDictContent(dfs[\"presentation_title\"],'ja','en','')\n","                    pdate=dfs[\"publication_date\"]\n","                    TalksDict[i]={}\n","                    TalksDict[i][\"presenter\"]=fullnameJP\n","                    if allenglish:\n","                        TalksDict[i]['printname']=fullname\n","                    else:\n","                        TalksDict[i][\"printname\"]=fullnameJP\n","                    TalksDict[i][\"event\"]=ename\n","                    TalksDict[i][\"presentation_title\"]=ptitle\n","                    TalksDict[i][\"date\"]=pdate\n","                    TalksDict[i][\"han\"]=han\n","                    TalksDict[i][\"invited\"]=ReturnDictWOerror(dfs,'invited',False)\n","                    TalksDict[i][\"international\"]=ReturnDictWOerror(dfs,'is_international_presentation',False)\n","                    TalksDict[i][\"keyoral\"]= ReturnDictWOerror(dfs,\"presentation_type\",'')\n","                    i=i+1\n","    if 'items' in dfSC.keys():\n","        for dfs in dfSC['items']:\n","            if 'from_event_date' in dfs.keys():\n","                if (dfs['from_event_date']>=mindate) & (dfs['from_event_date']<=maxdate):\n","                    SocialContDict[j]={}\n","                    SocialContDict[j]['name']=fullnameJP\n","                    SocialContDict[j][\"title\"]=dfs['social_contribution_title']['ja']\n","                    SocialContDict[j][\"date\"]=dfs['from_event_date']\n","                    SocialContDict[j][\"han\"]=han\n","                    if 'event' in dfs.keys():\n","                        SocialContDict[j][\"event\"]=ReturnDictContent(dfs[\"event\"],'ja','en','')\n","                    else:\n","                        SocialContDict[j][\"event\"]=''\n","                    j=j+1\n","    if 'items' in dfAw.keys():\n","        for dfs in dfAw['items']:\n","            if (dfs['award_date']>=mindate) & (dfs['award_date']<=maxdate):\n","                AwardsDict[l]={}\n","                AwardsDict[l]['name']=fullnameJP\n","                AwardsDict[l]['award_name']=ReturnDictContent(dfs['award_name'],'ja','en','')\n","                if 'association' in dfs.keys():\n","                    AwardsDict[l]['association']=ReturnDictContent(dfs['association'],'ja','en','')\n","                else:\n","                    AwardsDict[l]['association']=''\n","                AwardsDict[l]['award_date']=dfs['award_date']\n","                l=l+1"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{},"colab_type":"code","id":"hctp5YUnh0l4"},"outputs":[],"source":["#@title 書籍(books_etc)データの作成\n","booksDict={}\n","i=0\n","for ids,fullname,fullnameJP,dh,mindate,maxdate,han in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate,allHan):\n","  dfM = jsonfiles[ids][\"books_etc\"]\n","  if ignoremindate:\n","    mindate='0'\n","  if 'items' in dfM.keys():\n","    for dfs in dfM['items']:\n","      if all([a in dfs.keys() for a in ['authors',\"book_title\",\"publication_date\"]]):\n","        if (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n","          if ('ja' in dfs[\"authors\"].keys()):\n","              pname=dfs[\"authors\"][\"ja\"][0][\"name\"]\n","          else:\n","              pname=dfs[\"authors\"][\"en\"][0][\"name\"]\n","          ename=ReturnDictContent(dfs[\"book_title\"],'ja','en','')\n","          if \"book_owner_range\" in dfs.keys():\n","            eoname=\" \\'\"+ReturnDictContent(dfs[\"book_owner_range\"],'ja','en','')+\"\\',\"\n","          else:\n","            eoname=''\n","          if \"book_owner_role\" in dfs.keys():\n","            brole=\" (\"+dfs[\"book_owner_role\"]+\"),\"\n","          else:\n","            brole=','\n","          if \"publisher\" in dfs.keys():\n","            pub=\" \"+ReturnDictContent(dfs[\"publisher\"],'ja','en','')+\",\"\n","          else:\n","            pub=''\n","          pdate=dfs[\"publication_date\"]\n","          booksDict[i]={}\n","          booksDict[i]['authors']=fullname\n","          if allenglish:\n","            booksDict[i]['printname']=fullname\n","          else:\n","            booksDict[i]['printname']=fullnameJP\n","          booksDict[i][\"book_title\"]=' '+ename+','\n","          booksDict[i][\"book_owner_role\"]=brole\n","          booksDict[i][\"book_owner_range\"]=eoname\n","          booksDict[i][\"publisher\"]=pub\n","          booksDict[i][\"date\"]=pdate\n","          booksDict[i][\"han\"]=han\n","          i=i+1"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{},"colab_type":"code","id":"nFe7cnwg6qNv"},"outputs":[],"source":["#@title その他(MISC)データの作成\n","miscDict={}\n","medDict={}\n","i,j=0,0\n","for ids,fullname,fullnameJP,dh,mindate,maxdate,han in zip(allmembers,allnames,allnamesJP,allDaihyoBuntan,allmindate,allmaxdate,allHan):\n","  dfMis = jsonfiles[ids][\"misc\"]\n","\n","  if ignoremindate:\n","    mindate='0'\n","\n","  if 'items' in dfMis.keys():\n","    for dfs in dfMis['items']:\n","      if all([a in dfs.keys() for a in ['authors',\"paper_title\",\"publication_date\",\"publication_name\"]]):\n","        if  (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n","          if ('ja' in dfs[\"authors\"].keys()):\n","              pname=dfs[\"authors\"][\"ja\"][0][\"name\"]\n","          else:\n","              pname=dfs[\"authors\"][\"en\"][0][\"name\"]\n","          ename=ReturnDictContent(dfs[\"paper_title\"],'ja','en','')\n","          ptitle=ReturnDictContent(dfs[\"publication_name\"],'ja','en','')\n","          pdate=dfs[\"publication_date\"]\n","          miscDict[i]={}\n","          miscDict[i]['authors']=fullname\n","          if allenglish:\n","            miscDict[i]['printname']=fullname\n","          else:\n","            miscDict[i]['printname']=fullnameJP\n","\n","          miscDict[i][\"paper_title\"]=' \\''+ename+'\\','\n","          miscDict[i][\"publication_name\"]=' '+ptitle+','\n","          miscDict[i][\"date\"]=pdate\n","          miscDict[i][\"han\"]=han\n","          i=i+1\n","  dfMed = jsonfiles[ids][\"media_coverage\"]\n","  if 'items' in dfMed.keys():\n","    for dfs in dfMed['items']:\n","      if all([a in dfs.keys() for a in [\"media_coverage_title\",\"publication_date\"]]):\n","        if  (dfs[\"publication_date\"]>=mindate) & (dfs[\"publication_date\"]<=maxdate):\n","          ename=ReturnDictContent(dfs[\"media_coverage_title\"],'ja','en','')\n","          pdate=dfs[\"publication_date\"]\n","          medDict[j]={}\n","          medDict[j]['authors']=fullname\n","          if allenglish:\n","            medDict[j]['printname']=fullname\n","          else:\n","            medDict[j]['printname']=fullnameJP\n","          medDict[j][\"media_coverage_type\"]=''\n","          if \"media_coverage_type\" in dfs.keys():\n","            medDict[j][\"media_coverage_type\"]=dfs[\"media_coverage_type\"]\n","          ptitle=''\n","          if \"publisher\" in dfs.keys():\n","            ptitle=ReturnDictContent(dfs[\"publisher\"],'ja','en','')+', '\n","\n","          petitle=''\n","          if \"event\" in dfs.keys():\n","            petitle=ReturnDictContent(dfs[\"event\"],'ja','en','')+','\n","#          print(' '+ptitle+petitle)\n","\n","          pltitle=''\n","          if \"location\" in dfs.keys():\n","            pltitle=ReturnDictContent(dfs[\"location\"],'ja','en','')+','\n","#          print(' '+ptitle+petitle+pltitle)\n","\n","          medDict[j][\"paper_title\"]=' \\''+ename+'\\','\n","          medDict[j][\"publication_name\"]=' '+ptitle+petitle+pltitle\n","          medDict[j][\"date\"]=pdate\n","          medDict[j][\"han\"]=han\n","          j=j+1"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#@title docxを作成\n","document = Document()\n","\n","section = document.sections[0]\n","section.left_margin = Mm(15)\n","section.right_margin = Mm(15)\n","section.top_margin = Mm(15)\n","section.bottom_margin = Mm(15)\n","\n","nameListPrint=SurnameFirstList(nameList,'Okada')\n","\n","if peer_reviewed:\n","    refbool=[True]\n","else:\n","    refbool=[True,False]\n","\n","if ryoiki_linked:\n","    ryoikibool=[True]\n","else:\n","    ryoikibool=[True,False]\n","\n","for han in np.unique(allHan):\n","\n","    PapersDictSelected={k:PapersDict[k] for k in range(len(PapersDict)) if (PapersDict[k]['date']>globalmindate) & (PapersDict[k]['date']<globalmaxdate)  & (PapersDict[k]['referee'] in refbool) & (PapersDict[k]['han']==han) & (PapersDict[k]['ryoiki'] in ryoikibool)}\n","    TalksDictSelected={k:TalksDict[k] for k in range(len(TalksDict)) if (TalksDict[k]['date']>globalmindate) & (TalksDict[k]['date']<globalmaxdate) & (TalksDict[k]['han']==han)}\n","    booksDictSelected={k:booksDict[k] for k in range(len(booksDict)) if (booksDict[k]['date']>globalmindate) & (booksDict[k]['date']<globalmaxdate) & (booksDict[k]['han']==han)}\n","    SocialContDictSelected= {k:SocialContDict[k] for k in range(len(SocialContDict)) if (SocialContDict[k]['date']>globalmindate) & (SocialContDict[k]['date']<globalmaxdate) & (SocialContDict[k]['han']==han)}\n","    miscDictSelected={k:miscDict[k] for k in range(len(miscDict)) if (miscDict[k]['date']>globalmindate) & (miscDict[k]['date']<globalmaxdate) & (miscDict[k]['han']==han)}\n","    medDictSelected={k:medDict[k] for k in range(len(medDict)) if (medDict[k]['date']>globalmindate) & (medDict[k]['date']<globalmaxdate) & (medDict[k]['han']==han)}\n","\n","    keys=list(PapersDictSelected.keys())\n","    datelist=[PapersDictSelected[r]['date'] for r in keys]\n","    arg=np.argsort(datelist)[::-1]\n","\n","    document.add_paragraph(han[0]+'0'+han[1]+'班')\n","\n","    countBSM=len(booksDictSelected)+len(SocialContDictSelected)+len(miscDictSelected)\n","\n","    if countBSM < maxBSM:\n","        maxpaps=maxpap+maxBSM-countBSM\n","    else:\n","        maxpaps=maxpap\n","    #print(countBSM)\n","    textmax= ', うち'+str(min(maxpaps,len(arg)))+'件抜粋'# if inds>maxpaps else ''\n","    CountR=document.add_paragraph('<原著論文> 査読有計'+str(len(arg))+'件'+textmax)\n","    CountR.runs[0].bold=True\n","    inds=0\n","    for r in arg:\n","        pap=PapersDictSelected[keys[r]]\n","        ## to eliminate duplicates of papers\n","        # based on DOI\n","        if len(doiDict[pap['doi']]['name'])>1:\n","            if doiDict[pap['doi']]['count']==1:\n","                continue;\n","            titleDict[pap['papid']]['count']=1\n","            doiDict[pap['doi']]['count']=1\n","        # based on paper title\n","        if (len(titleDict[pap['papid']]['name'])>1):\n","            if titleDict[pap['papid']]['count']==1:\n","                continue;\n","            titleDict[pap['papid']]['count']=1\n","            doiDict[pap['doi']]['count']=1\n","        inds=inds+1\n","        if inds<=maxpaps:\n","            if pap['issues']:\n","                p = document.add_paragraph('***')\n","            if numberingPapers:\n","                if pap['referee']:\n","                    p = document.add_paragraph(str(inds)+'. ')\n","                else:\n","                    p = document.add_paragraph(preprintmark+str(inds)+'. ')\n","            else:\n","                if pap['referee']:\n","                    p = document.add_paragraph('')\n","                else:\n","                    p = document.add_paragraph(preprintmark)\n","\n","            for nm in pap['authors']:\n","                if nm in nameListPrint:\n","                    listedCorrespo = any([c for c,n in zip(doiDict[pap['doi']]['Corresp'] + titleDict[pap['papid']]['Corresp'] , doiDict[pap['doi']]['name'] + titleDict[pap['papid']]['name']) if n==nm])\n","                    # print(nm,listedCorrespo)\n","                    # if pap['Corresp'] | listedCorrespo:\n","                    #     p.add_run('*')\n","                    if daihyobuntanList[nameListPrint.index(nm)]=='D':\n","                        run=p.add_run()\n","                        run.text=nm\n","                        run.underline = WD_UNDERLINE.DOUBLE\n","                        run.font.bold =True\n","                    elif daihyobuntanList[nameListPrint.index(nm)]=='B':\n","                        run=p.add_run()\n","                        run.text=nm\n","                        run.underline = True\n","                        run.font.bold =True\n","                    else:\n","                        p.add_run(nm)\n","                else:\n","                    p.add_run(nm)\n","                p.add_run(', ')\n","            p.add_run(pap['text1'])\n","            p.add_run(pap['text2'])\n","\n","    if inds != len(arg):\n","        textmax= ', うち'+str(min(maxpaps,inds))+'件抜粋'# if inds>maxpaps else ''\n","        CountR.text='<原著論文> 査読有計'+str(inds)+'件'+textmax\n","        CountR.runs[0].bold=True\n","        #replaced_text = paragraph.text.replace(\"before\",\"after\")\n","\n","    for r in keys:\n","        doiDict[PapersDictSelected[r]['doi']]['count']=0\n","        titleDict[PapersDictSelected[r]['papid']]['count']=0\n","\n","\n","    keys=list(TalksDictSelected.keys())\n","    datelist=[TalksDictSelected[r]['date'] for r in keys]\n","    arg=np.argsort(datelist)[::-1]\n","    #document.add_paragraph('')\n","    textmax= ', うち'+str(min(maxtalk,len(arg)))+'件抜粋'# if len(arg)>maxtalk else ''\n","    CountG=document.add_paragraph('<学会発表・講演> 計'+str(len(arg))+'件'+textmax)\n","    CountG.runs[0].bold=True\n","\n","    inds=0\n","    for r in arg:\n","        inds=inds+1\n","        if inds<=maxtalk:\n","            pap=TalksDictSelected[keys[r]]\n","            p = document.add_paragraph(str(inds)+'. ')\n","            nm=pap[\"presenter\"]\n","            p.add_run(pap[\"printname\"])\n","            p.add_run(', \\\"'+pap[\"presentation_title\"]+\"\\\"\")\n","            p.add_run(', '+pap[\"event\"])\n","            p.add_run(', '+pap[\"date\"]+'.')\n","\n","    keys=list(booksDictSelected.keys())\n","    datelist=[booksDictSelected[r]['date'] for r in keys]\n","    arg=np.argsort(datelist)[::-1]\n","    #document.add_paragraph('')\n","    CountB=document.add_paragraph('<書籍> 計'+str(len(arg))+'件')\n","    CountB.runs[0].bold=True\n","    inds=0\n","    for r in arg:\n","        inds=inds+1\n","        pap=booksDictSelected[keys[r]]\n","        p = document.add_paragraph(str(inds)+'. ')\n","        nm=pap['authors']\n","        p.add_run(pap[\"printname\"]) \n","        p.add_run(pap[\"book_owner_role\"])\n","        p.add_run(pap[\"book_owner_range\"])\n","        p.add_run(pap[\"book_title\"])\n","        p.add_run(pap[\"publisher\"])\n","        p.add_run(' '+pap[\"date\"][:7]+'.')\n","\n","    keys=list(SocialContDictSelected.keys())\n","    datelist=[SocialContDictSelected[r]['date'] for r in keys]\n","    arg=np.argsort(datelist)[::-1]\n","    textmax= ', うち'+str(min(maxsocial,len(arg)))+'件抜粋'# if len(arg)>maxsocial else ''\n","    CountO=document.add_paragraph('<アウトリーチ> 計'+str(len(arg))+'件'+textmax)\n","    CountO.runs[0].bold=True\n","    inds=0\n","    for r in arg:\n","        inds=inds+1\n","        if inds<=maxsocial:\n","            pap=SocialContDictSelected[keys[r]]\n","            p = document.add_paragraph(str(inds)+'. ')\n","            p.add_run(pap[\"name\"])\n","            p.add_run(', '+pap[\"title\"])\n","            p.add_run(', '+pap[\"event\"])\n","            p.add_run(' '+pap[\"date\"]+'.')\n","\n","    keys=list(medDictSelected.keys())\n","    datelist=[medDictSelected[r]['date'] for r in keys]\n","    arg=np.argsort(datelist)[::-1]\n","    #document.add_paragraph('')\n","    textmax= ', うち'+str(min(maxmed,len(arg)))+'件抜粋'# if len(arg)>maxmed else ''\n","    CountP=document.add_paragraph('<報道> 計'+str(len(arg))+'件'+textmax)\n","    CountP.runs[0].bold=True\n","    inds=0\n","    for r in arg:\n","        inds=inds+1\n","        if inds<=maxsonota:\n","            pap=medDictSelected[keys[r]]\n","            p = document.add_paragraph(str(inds)+'. ')\n","            nm=pap['authors']\n","            p.add_run(pap[\"printname\"])\n","            p.add_run(','+pap[\"paper_title\"])\n","            p.add_run(pap[\"publication_name\"])\n","            p.add_run(' '+pap[\"date\"]+'.')\n","\n","    keys=list(miscDictSelected.keys())\n","    datelist=[miscDictSelected[r]['date'] for r in keys]\n","    arg=np.argsort(datelist)[::-1]\n","    #document.add_paragraph('')\n","    textmax= ', うち'+str(min(maxsonota,len(arg)))+'件抜粋'# if len(arg)>maxsonota else ''\n","    CountM=document.add_paragraph('<その他> 計'+str(len(arg))+'件'+textmax)\n","    CountM.runs[0].bold=True\n","    inds=0\n","    for r in arg:\n","        inds=inds+1\n","        if inds<=maxsonota:\n","            pap=miscDictSelected[keys[r]]\n","            p = document.add_paragraph(str(inds)+'. ')\n","            nm=pap['authors']\n","            p.add_run(pap[\"printname\"])\n","            p.add_run(','+pap[\"paper_title\"])\n","            p.add_run(pap[\"publication_name\"])\n","            p.add_run(' '+pap[\"date\"]+'.')\n","    p = document.add_paragraph()\n","\n","    p.add_run().add_break(WD_BREAK.PAGE) # page break\n","\n","for paragraph in document.paragraphs:\n","    paragraph.style = document.styles['Normal']\n","    paragraph.paragraph_format.space_before = Pt(2)\n","    paragraph.paragraph_format.space_after = Pt(2)\n","    for run in paragraph.runs:\n","        run.font.size = Pt(docoutputpointsize)\n","document.save(file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title ファイル出力\n","if ('google.colab' in str(get_ipython())):\n","    files.download(file_name)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"researchmapv2_to_docx.ipynb","provenance":[]},"interpreter":{"hash":"c3500e5973634b4432116d19786601ecc506aed96e4bde06851a6f10663e815f"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"metadata":{"interpreter":{"hash":"b6aaa8c452f1aa53401d42c477fe97baeea39d8952471e90cdbb23434ceb6c90"}},"toc":{"colors":{"hover_highlight":"#DAA520","navigate_num":"#000000","navigate_text":"#333333","running_highlight":"#FF0000","selected_highlight":"#FFD700","sidebar_border":"#EEEEEE","wrapper_background":"#FFFFFF"},"moveMenuLeft":true,"nav_menu":{"height":"12px","width":"252px"},"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":4,"toc_cell":false,"toc_section_display":"block","toc_window_display":false,"widenNotebook":false}},"nbformat":4,"nbformat_minor":2}
